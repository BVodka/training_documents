Readme

# This is the repo contains training materials forDP-100 for my study group 

1. Slides 
- https://docs.google.com/presentation/d/1tZ3YAHE6KAiB4JfQYApFW9-ZBL3WqgK1bkSjd6OtwJE/edit?usp=sharing
2. Records https://www.youtube.com/playlist?list=PLBIstIrTTexVulC2uKN6q1VYesR18nBPS
3. Blog posts
- Khalid's post - https://www.linkedin.com/pulse/microsoft-azure-data-scientist-exam-dp-100-khalid-waleed/?trackingId=Xr42VxxDQ5eIKtCFQKQC9w%3D%3D
- my post https://janebraine.tech/tag/dp-100/
-----------------------------------------------------------------
## Area of focus 
A large part of the exam will be on Azure SDK 
### Data Science general knowledge 
- Basic statistics and data visualization
- Normalization ( data preparation )
- **Evaluation metrics , what each metrics signal - what is the best metric for certain usecase 
- Cross validation
- ** Hyper parameter tuning (hyperdrive) **
- ** Different sampling method ( parameter for hyperdrive **
- 
- Feature selections ( which method for which case )
- Requires business understanding of 3 mains algorithms , anomaly detection, recommendation, utilize different data sources depends on business use case 
### Azure services 
- Apply business scenarios
- 1 question on databricks , virtual machine 
- ***Make sure to do the labs in class twice, and the github lab (1A, 1B ,2A, 2B) and make sure to understand the labs - really practice on this and understand the syntax and functions. E.g if there is an endpoint for an object then what functions the object could have . Do the lab and takes your own note
- **Focus on Azure SDK python** - a large content of the exam will be testing on this
- ML Designer pipelines ( training and ingest pipeline ) - a few 
- AutoML : automl for forecasting , decision making  ml designer in azure ML workspace - very important 
- Train model using estimator -e.g Pytorch ( estimator )
- *Code* get resources in Azure infrastructure here
- *Code* Loading, attaching, download, mounting, import data from *datastore*,*dataset* , deploy models and pipeline, consume pipeline, method of deployment from a script here, method of predicting
- Focus on lesson #6 Udacity Azure 
- (AKS, SDK- enviroments, benefits ) : https://docs.microsoft.com/en-us/learn/modules/use-automated-machine-learning/deploy-model
- How to invoke API for batch inference API ( 3 parameters ) , real-time inference / steaming API 
- Metadata - importing share explainner- a few 
- Small sections on contrainst of Microsoft infrastructure in the infrastructures 
- sequence questions - what are the steps to perform data science flow ( split data into sampling, random number, train data)
- Scenario and choose best options
- streaming hyper paramters
- Very few on autoML and designer 
- Best process to parse arguement, mountdatastore in your dataset 
- SDK syntax for autoMl 
- Roles and granting controls : data science vs it admins
- deploying containers and moving containers with pytorch
- troubleshooting AKS
- DP-100 lab 4 : how to create a compute
- how to write logs and read log results
*** there are questions you can not go back and review . make sure to read these well **
*** Be aware of the mock questions available online, a lot of the answers are not right **




